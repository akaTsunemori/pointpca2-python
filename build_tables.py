import pandas as pd
import numpy as np
import argparse
from os.path import exists, join
from os import makedirs, listdir
import matlab.engine
from pointpca2 import lc_pointpca
from absl import app
from absl.flags import argparse_flags


def get_latest_csv(filenames):
    if not filenames:
        return None, None
    latest_true = None
    latest_pred = None
    max_true_number = -1
    max_pred_number = -1
    for filename in filenames:
        parts = filename.split('_')
        if len(parts) != 4:
            return None, None
        number, _, _, status_with_extension = parts
        status = status_with_extension.split('.')[0]
        try:
            number = int(number)
        except ValueError:
            return None, None
        if status == 'true' and number > max_true_number:
            max_true_number = number
            latest_true = filename
        elif status == 'pred' and number > max_pred_number:
            max_pred_number = number
            latest_pred = filename
    return latest_true, latest_pred


def main(args):
    eng = matlab.engine.start_matlab()
    pointpca_path = join(args.pointpca2_path, 'Matlab_FeatureExtraction', 'lib')
    eng.addpath(pointpca_path, nargout=0)
    print('MATLAB engine for Python successfully started!')
    if not exists('./tables'):
        makedirs('./tables', exist_ok=True)
    df_dataset = pd.read_csv(args.df_dataset_path)
    df_dataset['SIGNAL'] = df_dataset['SIGNAL'].str.strip()
    df_dataset['REF'] = df_dataset['REF'].str.strip()
    df_dataset['LOCATION'] = df_dataset['LOCATION'].str.strip()
    df_dataset['REF_LOCATION'] = df_dataset['REF_LOCATION'].str.strip()
    # df_dataset['LOCATION'] = df_dataset['LOCATION'].str.replace(
    #     '/home/pedro/databases/QualityDatabases/PointClouds/reference_APSIPA/', '/home/arthurc/Documents/APSIPA/')
    # df_dataset['REFLOCATION'] = df_dataset['REFLOCATION'].str.replace(
    #     '/home/pedro/databases/QualityDatabases/PointClouds/reference_APSIPA/', '/home/arthurc/Documents/APSIPA/')
    FEATURES = [f'FEATURE_{i+1}' for i in range(40)]
    tables = listdir('./tables')
    true_filename, pred_filename = get_latest_csv(tables)
    if not true_filename and not pred_filename and len(tables) > 0:
        raise Exception('tables folder must be empty or contain only csv files generated by this script!')
    common_columns = ['SIGNAL', 'REF', 'SCORE']
    if not pred_filename:
        df_result_pred = pd.DataFrame(columns=common_columns +[*FEATURES])
        df_result_pred[common_columns] = df_dataset[common_columns]
    else:
        df_result_pred = pd.read_csv(f'tables/{pred_filename}', index_col=0)
    if not true_filename:
        df_result_true = pd.DataFrame(columns=common_columns + [*FEATURES])
        df_result_true[common_columns] = df_dataset[common_columns]
    else:
        df_result_true = pd.read_csv(f'tables/{true_filename}', index_col=0)
    for index, row in df_dataset.iterrows():
        output_true = f'tables/{index:03}_{args.dataset_basename}_Matlab.csv'
        output_pred = f'tables/{index:03}_{args.dataset_basename}_Python.csv'
        exists_true = exists(output_true)
        exists_pred = exists(output_pred)
        signal, ref = row['SIGNAL'], row['REF']
        signal_location, ref_location = row['LOCATION'], row['REF_LOCATION']
        print(f'{index}/{len(df_dataset)}')
        print('REF/SIGNAL:', ref, signal)
        try:
            print('\tComputing lc_pointpca true')
            if not exists_true:
                lcpointpca_true = eng.lc_pointpca(
                    f'{signal_location}/{signal}',
                    f'{ref_location}/{ref}',
                    nargout=1)
                lcpointpca_true = np.array(lcpointpca_true)
                print(f'\t\tDone!')
            else:
                print(f'\t\tFound checkpoint at "{output_true}", skipping...')
            print('\tComputing lc_pointpca predicted')
            if not exists_pred:
                lcpointpca_pred = lc_pointpca(
                    f'{signal_location}/{signal}',
                    f'{ref_location}/{ref}')
                print(f'\t\tDone!')
            else:
                print(f'\t\tFound checkpoint at "{output_pred}", skipping...')
        except Exception as e:
            print(e)
            continue
        for i in range(len(FEATURES)):
            if not exists_true:
                df_result_true.at[index, FEATURES[i]] = lcpointpca_true[i]
            if not exists_pred:
                df_result_pred.at[index, FEATURES[i]] = lcpointpca_pred[i]
        if not exists_true or not exists_pred:
            print('\tSaving checkpoints to disk')
        if not exists_true:
            df_result_true.to_csv(output_true)
        if not exists_pred:
            df_result_pred.to_csv(output_pred)
    eng.quit()


def parse_args(argv):
    parser = argparse_flags.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--pointpca2_path',
        type=str,
        required=True,
        help='Path to pointpca+ repository.'
    )
    parser.add_argument(
        '--df_dataset_path',
        type=str,
        required=True,
        help='DataFrame path representing the database.',
        default='/home/arthurc/Documents/APSIPA/apsipa.csv'
    )
    parser.add_argument(
        '--dataset_basename',
        type=str,
        required=True,
        help='Name of dataset to be used as reference (base) to output files.',
        default='APSIPA'
    )
    
 
    return parser.parse_args(argv[1:])


if __name__ == "__main__":
    app.run(main, flags_parser=parse_args)
